# import re
# import json
# import os
# import time
# from google.cloud import vision
# from docx import Document
# import openai
# from dotenv import load_dotenv

# load_dotenv()
# openai.api_key = os.getenv("OPENAI_API_KEY")
# os.environ["GOOGLE_APPLICATION_CREDENTIALS"] = os.getenv("GOOGLE_APPLICATION_CREDENTIALS")

# def extract_text_with_vision_api(image_path):
#     """–†–∞—Å–ø–æ–∑–Ω–∞—ë—Ç —Ç–µ–∫—Å—Ç —Å –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è —Å –ø–æ–º–æ—â—å—é Google Vision API."""
#     client = vision.ImageAnnotatorClient()

#     with open(image_path, 'rb') as image_file:
#         content = image_file.read()
#     image = vision.Image(content=content)

#     response = client.text_detection(image=image)
#     texts = response.text_annotations

#     if not texts:
#         print("–¢–µ–∫—Å—Ç –Ω–µ –Ω–∞–π–¥–µ–Ω –Ω–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–∏.")
#         return ""

#     return texts[0].description

# def process_with_openai(text):
#     """–û–±—Ä–∞–±–æ—Ç–∫–∞ —Ç–µ–∫—Å—Ç–∞ —Å –ø–æ–º–æ—â—å—é OpenAI."""
#     for attempt in range(3):
#         try:
#             prompt = f"""
#             You are a professional translator specializing in passport documents. Follow these rules STRICTLY:
#             The passport has been provided in Kazakh language. You need to translate from KZ to RUS
#             If dates already provided in Russian language, return this data
#             1. Names (Surname, Given Names, Father's Name) must remain in their original language. Do NOT translate them.
#             2. Geographic names (Place of Birth, Authority) should be translated into Russian only if they are in Latin script. For example:
#             - "Tashkent" -> "–¢–∞—à–∫–µ–Ω—Ç"
#             - "Almaty" -> "–ê–ª–º–∞—Ç—ã"
#             - "–¢–∞—à–∫–µ–Ω—Ç" -> "–¢–∞—à–∫–µ–Ω—Ç" (no translation needed)
#             3. Nationality should be translated into Russian only if it is in Latin script. For example:
#             - "Uzbekistan" -> "–£–∑–±–µ–∫–∏—Å—Ç–∞–Ω"
#             - "“ö–∞–∑–∞“õ—Å—Ç–∞–Ω" -> "“ö–∞–∑–∞“õ—Å—Ç–∞–Ω" (no translation needed)
#             4. Return ONLY the translated text. Do NOT add explanations or notes.
#             5. If Name, surname, place of Birth already in Kazakh language, don't tranclate, 
#             Text to translate:

#             {text}

#             Fields to extract (JSON only):
#             1. Type (e.g., "P")
#             2. Code
#             3. Passport Number
#             4. Surname (original)
#             5. Given Names (original)
#             6. Nationality (translate to Russian if in Latin)
#             7. Date of Birth (dd.mm.yyyy)
#             8. Sex ("–ñ" for F, "–ú" for M)
#             9. Authority (exact value)
#             10. ID Number
#             11. Place of Birth (translate to Russian if in Latin)
#             12. Date of Issue (dd.mm.yyyy)
#             13. Date of Expiry (dd.mm.yyyy)

#             If a field is missing, write "Not found".
#             """

#             response = openai.ChatCompletion.create(
#                 model="gpt-4",
#                 messages=[
#                     {"role": "system", "content": "You are a helpful assistant."},
#                     {"role": "user", "content": prompt}
#                 ]
#             )
#             result = re.sub(r'^.*?{', '{', result, flags=re.DOTALL)  # –£–¥–∞–ª–∏—Ç—å –≤—Å—ë –¥–æ –ø–µ—Ä–≤–æ–π {
#             result = re.sub(r'}.*?$', '}', result, flags=re.DOTALL)  # –£–¥–∞–ª–∏—Ç—å –≤—Å—ë –ø–æ—Å–ª–µ –ø–æ—Å–ª–µ–¥–Ω–µ–π }
#             result = response["choices"][0]["message"]["content"].strip()
#             try:
#                 # –£–¥–∞–ª—è–µ–º –ø–æ—Ç–µ–Ω—Ü–∏–∞–ª—å–Ω—ã–µ –ª–∏—à–Ω–∏–µ —Å—Ç—Ä–æ–∫–∏
#                 start = result.find("{")
#                 end = result.rfind("}")
#                 if start != -1 and end != -1:
#                     result = result[start:end + 1]
#                     json.loads(result)  # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ —ç—Ç–æ –∫–æ—Ä—Ä–µ–∫—Ç–Ω—ã–π JSON
#                     return result
#             except json.JSONDecodeError:
#                 pass

#             print(f"–ü–æ–ø—ã—Ç–∫–∞ {attempt + 1}: –ù–µ–∫–æ—Ä—Ä–µ–∫—Ç–Ω—ã–π JSON –æ—Ç OpenAI.")
#             time.sleep(2)  # –ó–∞–¥–µ—Ä–∂–∫–∞ –ø–µ—Ä–µ–¥ –ø–æ–≤—Ç–æ—Ä–Ω–æ–π –ø–æ–ø—ã—Ç–∫–æ–π
#         except Exception as e:
#             print(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ —Ç–µ–∫—Å—Ç–∞ —Å –ø–æ–º–æ—â—å—é OpenAI (–ø–æ–ø—ã—Ç–∫–∞ {attempt + 1}): {e}")
#             time.sleep(2)  # –ó–∞–¥–µ—Ä–∂–∫–∞ –ø–µ—Ä–µ–¥ –ø–æ–≤—Ç–æ—Ä–Ω–æ–π –ø–æ–ø—ã—Ç–∫–æ–π
            
#     print("OpenAI –Ω–µ —Å–º–æ–≥ –≤–µ—Ä–Ω—É—Ç—å –∫–æ—Ä—Ä–µ–∫—Ç–Ω—ã–π JSON –ø–æ—Å–ª–µ 3 –ø–æ–ø—ã—Ç–æ–∫.")
#     return "{}"

# def is_already_translated(text):
#     """–ü—Ä–æ–≤–µ—Ä—è–µ—Ç, –Ω–∞–ø–∏—Å–∞–Ω –ª–∏ —Ç–µ–∫—Å—Ç –Ω–∞ –Ω—É–∂–Ω–æ–º —è–∑—ã–∫–µ."""
#     cyrillic_chars = set("–ê–ë–í–ì–î–ï–Å–ñ–ó–ò–ô–ö–õ–ú–ù–û–ü–†–°–¢–£–§–•–¶–ß–®–©–™–´–¨–≠–Æ–Ø")
#     return any(char in cyrillic_chars for char in text)

# def translate_field(field_name, field_value, target_language="ru"):
#     """–ü–µ—Ä–µ–≤–æ–¥–∏—Ç –∑–Ω–∞—á–µ–Ω–∏–µ –ø–æ–ª—è —á–µ—Ä–µ–∑ OpenAI."""
#     if re.search("[–∞-—è–ê-–Ø–Å—ë]", field_value):
#         return field_value  #
#     try:
#         if is_already_translated(field_value):  # –ù–æ–≤–∞—è —Ñ—É–Ω–∫—Ü–∏—è –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏
#             return field_value  # –í–æ–∑–≤—Ä–∞—â–∞–µ–º –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω–æ–µ –∑–Ω–∞—á–µ–Ω–∏–µ

#         prompt = f"""
#         Translate the following into {target_language}:
#         {field_value}
#         """
#         response = openai.ChatCompletion.create(
#             model="gpt-4",
#             messages=[
#                 {"role": "system", "content": "You are a helpful assistant."},
#                 {"role": "user", "content": prompt}
#             ]
#         )
#         return response["choices"][0]["message"]["content"].strip()
#     except Exception as e:
#         print(f"–û—à–∏–±–∫–∞ –ø–µ—Ä–µ–≤–æ–¥–∞ –¥–ª—è –ø–æ–ª—è {field_name}: {e}")
#         return field_value

# def extract_and_fix_mrz_with_gpt(full_text):
#     """–ò–∑–≤–ª–µ–∫–∞–µ—Ç –∏ –∏—Å–ø—Ä–∞–≤–ª—è–µ—Ç MRZ –∏–∑ –ø–æ–ª–Ω–æ–≥–æ —Ç–µ–∫—Å—Ç–∞ —Å –ø–æ–º–æ—â—å—é OpenAI."""
#     try:
#         prompt = f"""
#         The following text is extracted from a passport image and contains the Machine Readable Zone (MRZ).
#         Your task is to:
#         1. Locate all lines that belong to the MRZ.
#         2. Merge them into exactly two lines, following the ICAO standard.
#         3. Ensure no data is lost during merging, even if the MRZ is split into more than two lines in the input text.
#         4. The MRZ should:
#             - Start with 'P<'.
#             - Have two lines.
#             - End the second line with a number.
#         5. Write only MRZ, without unneccerry information 

#         Text to process:
#         {full_text}

#         Provide only the corrected MRZ in two lines, ensuring all fields are present and properly formatted.
#         """
        
#         response = openai.ChatCompletion.create(
#             model="gpt-4",
#             messages=[
#                 {"role": "system", "content": "You are a helpful assistant that processes MRZ data from passport text."},
#                 {"role": "user", "content": prompt}
#             ]
#         )
        
#         # –ü–æ–ª—É—á–∞–µ–º –æ—Ç–≤–µ—Ç GPT
#         fixed_mrz = response["choices"][0]["message"]["content"].strip()
#         return fixed_mrz
#     except Exception as e:
#         print(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –∏–∑–≤–ª–µ—á–µ–Ω–∏–∏ –∏ –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–∏–∏ MRZ —Å –ø–æ–º–æ—â—å—é GPT: {e}")
#         return "MRZ –Ω–µ –Ω–∞–π–¥–µ–Ω–æ"

# def fill_word_template(template_path, output_path, data):
#     """–ó–∞–ø–æ–ª–Ω—è–µ—Ç —à–∞–±–ª–æ–Ω Word –¥–∞–Ω–Ω—ã–º–∏, –≤–∫–ª—é—á–∞—è —Ç–µ–∫—Å—Ç –≤–Ω—É—Ç—Ä–∏ —Ç–∞–±–ª–∏—Ü."""
#     doc = Document(template_path)

#     # –û–±—Ä–∞–±–æ—Ç–∫–∞ —Ç–µ–∫—Å—Ç–∞ –≤ –ø–∞—Ä–∞–≥—Ä–∞—Ñ–∞—Ö
#     for paragraph in doc.paragraphs:
#         for key, value in data.items():
#             if f"{{{{{key}}}}}" in paragraph.text:
#                 for run in paragraph.runs:
#                     if f"{{{{{key}}}}}" in run.text:
#                         run.text = run.text.replace(f"{{{{{key}}}}}", value.upper())

#     # –û–±—Ä–∞–±–æ—Ç–∫–∞ —Ç–µ–∫—Å—Ç–∞ –≤–Ω—É—Ç—Ä–∏ —Ç–∞–±–ª–∏—Ü
#     for table in doc.tables:
#         for row in table.rows:
#             for cell in row.cells:
#                 # –û–±—Ä–∞–±–æ—Ç–∫–∞ –∫–∞–∂–¥–æ–≥–æ –ø–∞—Ä–∞–≥—Ä–∞—Ñ–∞ –≤–Ω—É—Ç—Ä–∏ —è—á–µ–π–∫–∏
#                 for paragraph in cell.paragraphs:
#                     for key, value in data.items():
#                         if f"{{{{{key}}}}}" in paragraph.text:
#                             for run in paragraph.runs:
#                                 if f"{{{{{key}}}}}" in run.text:
#                                     run.text = run.text.replace(f"{{{{{key}}}}}", value.upper())

#     # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –¥–æ–∫—É–º–µ–Ω—Ç–∞
#     doc.save(output_path)
#     print(f"–î–∞–Ω–Ω—ã–µ —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤ —Ñ–∞–π–ª: {output_path}")

# def process_document(image_path, template_path, output_path):
#     """–ü–æ–ª–Ω—ã–π –ø—Ä–æ—Ü–µ—Å—Å: OCR -> –ü–µ—Ä–µ–≤–æ–¥ -> –ó–∞–ø–æ–ª–Ω–µ–Ω–∏–µ Word —à–∞–±–ª–æ–Ω–∞."""
#     try:
#         # 1. –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ —Ç–µ–∫—Å—Ç–∞ —Å –ø–æ–º–æ—â—å—é Google Vision API
#         print("–ò–∑–≤–ª–µ—á–µ–Ω–∏–µ —Ç–µ–∫—Å—Ç–∞ —Å –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è...")
#         recognized_text = extract_text_with_vision_api(image_path)
#         if not recognized_text:
#             print("–ò–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –Ω–µ —Å–æ–¥–µ—Ä–∂–∏—Ç —Ç–µ–∫—Å—Ç–∞.")
#             return

#         print("–†–∞—Å–ø–æ–∑–Ω–∞–Ω–Ω—ã–π —Ç–µ–∫—Å—Ç:")
#         print(recognized_text)

#         # 2. –û–±—Ä–∞–±–æ—Ç–∫–∞ —Ç–µ–∫—Å—Ç–∞ —Å –ø–æ–º–æ—â—å—é OpenAI
#         print("–û–±—Ä–∞–±–æ—Ç–∫–∞ —Ç–µ–∫—Å—Ç–∞ —Å –ø–æ–º–æ—â—å—é OpenAI...")
#         processed_data = process_with_openai(recognized_text)
        
#         # –ü—Ä–æ–≤–µ—Ä–∫–∞ –∏ —Ä–∞–∑–±–æ—Ä JSON
#         try:
#             structured_data = json.loads(processed_data)
#         except json.JSONDecodeError as e:
#             print(f"–û—à–∏–±–∫–∞ —Ä–∞–∑–±–æ—Ä–∞ JSON: {e}")
#             print("–û—Ç–≤–µ—Ç OpenAI:")
#             print(processed_data)
#             return

#         print("–ò–∑–≤–ª–µ—á—ë–Ω–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ:")
#         print(json.dumps(structured_data, indent=4, ensure_ascii=False))

#         keys = ["Code", "Passport Number", "Surname", "Given Names", "Nationality", "Date of Birth",
#                 "Sex", "Place of Birth", "Date of Issue", "Date of Expiry", "Authority", "MRZ"]
#         for key in keys:
#             if key not in structured_data:
#                 structured_data[key] = "Not specified"
#         #3          
#         print("–ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –∏ –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–∏–µ MRZ —Å –ø–æ–º–æ—â—å—é GPT...")
#         fixed_mrz = extract_and_fix_mrz_with_gpt(recognized_text)
#         structured_data["MRZ"] = fixed_mrz
#         print(f"–ò—Å–ø—Ä–∞–≤–ª–µ–Ω–Ω—ã–π MRZ: \n{fixed_mrz}")


#         print("–ü–µ—Ä–µ–≤–æ–¥ –¥–∞–Ω–Ω—ã—Ö:")
#         fields_to_translate = ["Surname", "Given Names", "Nationality", "Sex", "Place of Birth"]
#         for field in fields_to_translate:
#             if field in structured_data and structured_data[field] != "Not found":
#                 structured_data[field] = translate_field(field, structured_data[field], "ru")
#         print("–ü–µ—Ä–µ–≤–µ–¥—ë–Ω–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ:")
#         print(json.dumps(structured_data, indent=4, ensure_ascii=False))

#         # 5. –ó–∞–ø–æ–ª–Ω–µ–Ω–∏–µ —à–∞–±–ª–æ–Ω–∞ Word
#         fill_word_template(template_path, output_path, structured_data)

#     except Exception as e:
#         print(f"–û—à–∏–±–∫–∞: {e}")

# if __name__ == "__main__":
#     image_path = "C:\\images\\page1_uzb.jpg"  # –ü—É—Ç—å –∫ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—é
#     template_path = "C:\\images\\test_uzb.docx"  # –ü—É—Ç—å –∫ —à–∞–±–ª–æ–Ω—É Word
#     output_path = "C:\\images\\output_uzb.docx"
#     process_document(image_path, template_path, output_path)


# -----------------

import re
import json
import os
import time
from google.cloud import vision
from docx import Document
import openai
from dotenv import load_dotenv

# –ó–∞–≥—Ä—É–∑–∫–∞ API-–∫–ª—é—á–µ–π –∏–∑ .env —Ñ–∞–π–ª–∞
load_dotenv()
openai.api_key = os.getenv("OPENAI_API_KEY")
os.environ["GOOGLE_APPLICATION_CREDENTIALS"] = os.getenv("GOOGLE_APPLICATION_CREDENTIALS")

def extract_text_with_vision_api(image_path):
    """–†–∞—Å–ø–æ–∑–Ω–∞—ë—Ç —Ç–µ–∫—Å—Ç —Å –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è —Å –ø–æ–º–æ—â—å—é Google Vision API."""
    print("\nüîç –ò–∑–≤–ª–µ–∫–∞–µ–º —Ç–µ–∫—Å—Ç —Å –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è...")
    client = vision.ImageAnnotatorClient()
    
    with open(image_path, 'rb') as image_file:
        content = image_file.read()
    image = vision.Image(content=content)

    response = client.text_detection(image=image)
    texts = response.text_annotations

    if not texts:
        print("‚ùå –¢–µ–∫—Å—Ç –Ω–µ –Ω–∞–π–¥–µ–Ω –Ω–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–∏.")
        return ""

    extracted_text = texts[0].description.strip()
    print(f"‚úÖ –ò–∑–≤–ª–µ—á—ë–Ω–Ω—ã–π —Ç–µ–∫—Å—Ç:\n{extracted_text[:500]}...")
    return extracted_text

def process_with_openai(text):
    """–û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç —Ç–µ–∫—Å—Ç —Å –ø–æ–º–æ—â—å—é OpenAI (–∏–∑–≤–ª–µ–∫–∞–µ—Ç –ø–∞—Å–ø–æ—Ä—Ç–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ)."""
    print("\nüì° –û—Ç–ø—Ä–∞–≤–ª—è–µ–º –¥–∞–Ω–Ω—ã–µ –≤ OpenAI –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏...")
    prompt = f"""
    You are processing a Kazakh passport. Return only JSON without any extra explanations.
    
    - Names (Surname, Given Names) **MUST BE TRANSLATED** to Russian.
    - Geographic names (Place of Birth, Authority) **MUST BE TRANSLATED**.
    - Nationality must be translated if written in Latin script.
    - DO NOT ADD EXTRA COMMENTS OR EXPLANATIONS.

    Extract the following data as JSON:
    - Type
    - Code
    - Passport Number
    - Surname (translate to Russian)
    - Given Names (translate to Russian)
    - Nationality (translate if in Latin)
    - Date of Birth (dd.mm.yyyy)
    - Sex ("–ñ" for F, "–ú" for M)
    - Authority (translate)
    - Place of Birth (translate)
    - Date of Issue (dd.mm.yyyy)
    - Date of Expiry (dd.mm.yyyy)

    Text to process:
    {text}
    """

    for _ in range(3):
        try:
            response = openai.ChatCompletion.create(
                model="gpt-4-turbo",
                messages=[{"role": "system", "content": "You are a professional AI that processes passports."},
                          {"role": "user", "content": prompt}],
                response_format={"type": "json_object"}
            )
            structured_data = json.loads(response["choices"][0]["message"]["content"])
            print(f"‚úÖ OpenAI –≤–µ—Ä–Ω—É–ª –¥–∞–Ω–Ω—ã–µ:\n{json.dumps(structured_data, indent=4, ensure_ascii=False)}")
            return structured_data
        except Exception as e:
            print(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ OpenAI: {e}")
            time.sleep(2)
    return {}

def fill_word_template(template_path, output_path, data):
    """–ó–∞–ø–æ–ª–Ω—è–µ—Ç —à–∞–±–ª–æ–Ω Word –¥–∞–Ω–Ω—ã–º–∏ –∏ —É–¥–∞–ª—è–µ—Ç placeholders."""
    print("\nüìù –ó–∞–ø–æ–ª–Ω—è–µ–º —à–∞–±–ª–æ–Ω Word...")
    doc = Document(template_path)

    for paragraph in doc.paragraphs:
        for key, value in data.items():
            if f"{{{{{key}}}}}" in paragraph.text:
                paragraph.text = paragraph.text.replace(f"{{{{{key}}}}}", value.upper())
    
    for table in doc.tables:
        for row in table.rows:
            for cell in row.cells:
                for paragraph in cell.paragraphs:
                    for key, value in data.items():
                        if f"{{{{{key}}}}}" in paragraph.text:
                            paragraph.text = paragraph.text.replace(f"{{{{{key}}}}}", value.upper())

    # –£–±–∏—Ä–∞–µ–º placeholders, –µ—Å–ª–∏ –¥–∞–Ω–Ω—ã–µ –Ω–µ –Ω–∞–π–¥–µ–Ω—ã
    for paragraph in doc.paragraphs:
        paragraph.text = re.sub(r'\{\{.*?\}\}', '', paragraph.text)

    for table in doc.tables:
        for row in table.rows:
            for cell in row.cells:
                for paragraph in cell.paragraphs:
                    paragraph.text = re.sub(r'\{\{.*?\}\}', '', paragraph.text)

    doc.save(output_path)
    print(f"‚úÖ –î–æ–∫—É–º–µ–Ω—Ç —Å–æ—Ö—Ä–∞–Ω—ë–Ω: {output_path}")

def process_document(image_path, template_path, output_path):
    """–û—Å–Ω–æ–≤–Ω–æ–π –ø—Ä–æ—Ü–µ—Å—Å: OCR -> –æ–±—Ä–∞–±–æ—Ç–∫–∞ -> –ø–µ—Ä–µ–≤–æ–¥ -> –∑–∞–ø–æ–ª–Ω–µ–Ω–∏–µ —à–∞–±–ª–æ–Ω–∞."""
    try:
        recognized_text = extract_text_with_vision_api(image_path)
        if not recognized_text:
            print("‚ùå –ò–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –Ω–µ —Å–æ–¥–µ—Ä–∂–∏—Ç —Ç–µ–∫—Å—Ç–∞.")
            return
        
        structured_data = process_with_openai(recognized_text)

        fill_word_template(template_path, output_path, structured_data)

        print("\nüéâ –ü—Ä–æ—Ü–µ—Å—Å –∑–∞–≤–µ—Ä—à—ë–Ω —É—Å–ø–µ—à–Ω–æ!")
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞: {e}")

if __name__ == "__main__":
    process_document("input.jpg", "template.docx", "output.docx")
